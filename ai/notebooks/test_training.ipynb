{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e93843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 243916 samples, 1081 classes\n",
      "Top class: 1363227 with 7208 samples\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from plant_care_ai.training.class_selection import get_most_popular_classes\n",
    "\n",
    "project_root = Path.cwd().parent \n",
    "data_path = project_root / \"data\" / \"plantnet_300K\"\n",
    "\n",
    "top_100, all_counts = get_most_popular_classes(str(data_path), top_k=100)\n",
    "print(f\"Top class: {top_100[0]} with {all_counts[top_100[0]]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c207ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '1363227'), (1, '1392475'), (2, '1356022')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = {species_id: i for i, species_id in enumerate(top_100)}\n",
    "idx_to_class = {i: species_id for i, species_id in enumerate(top_100)}\n",
    "num_classes = len(top_100)\n",
    "\n",
    "[v for v in class_to_idx.items()][:3]\n",
    "[v for v in idx_to_class.items()][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73223bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plant_care_ai.training.train import PlantTrainer\n",
    "\n",
    "config = {\n",
    "    \"data_dir\": \"../data/plantnet_300K\",\n",
    "    \"checkpoint_dir\": \"../checkpoints\",\n",
    "    \"experiment_name\": \"efficientnet_v2_top100\",\n",
    "    \n",
    "    \"subset_classes\": top_100,\n",
    "    \"train_samples_per_class\": 150,\n",
    "    \"val_samples_per_class\": 30,\n",
    "    \n",
    "    \"model\": \"efficientnetv2\",\n",
    "    \"variant\": \"b0\",\n",
    "    \"img_size\": 224,\n",
    "    \n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"augm_strength\": 0.4,\n",
    "    \"num_workers\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf5992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szczuru/projects/Plant-Care-Assistant-App/ai/notebooks/../src/plant_care_ai/training/train.py:70: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.scaler = torch.amp.GradScaler(\"cuda\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 243916 samples, 1081 classes\n",
      "Loaded 31118 samples, 1081 classes\n",
      "Total train samples in dataset: 243916\n",
      "Selected classes: 100\n",
      "Train samples: 15000\n",
      "Val samples: 3000\n",
      "Sample label: 26\n",
      "Label type: <class 'int'>\n",
      "Model output size: 100\n"
     ]
    }
   ],
   "source": [
    "trainer = PlantTrainer(config)\n",
    "trainer.prepare_data()\n",
    "\n",
    "sample_img, sample_label = trainer.train_loader.dataset[0]\n",
    "print(f\"Sample label: {sample_label}\")\n",
    "print(f\"Label type: {type(sample_label)}\")\n",
    "print(f\"Model output size: {trainer.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b41c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 243916 samples, 1081 classes\n",
      "Loaded 31118 samples, 1081 classes\n",
      "Total train samples in dataset: 243916\n",
      "Selected classes: 100\n",
      "\n",
      "Checkpoint dir: ../checkpoints/efficientnet_v2_top100\n",
      "Epochs: 20\n",
      "Train samples: 15000\n",
      "Val samples: 3000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/469 [00:00<?, ?it/s]/home/szczuru/.local/lib/python3.14/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "\tTrain: Loss=4.3811, Acc=3.25%\n",
      "\tVal:   Loss=4.2507, Top-1=4.63%, Top-5=18.97%\n",
      "\tLR: 0.000994\n",
      "Best model saved (acc: 4.63%)\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "\tTrain: Loss=4.0772, Acc=6.86%\n",
      "\tVal:   Loss=4.3713, Top-1=6.83%, Top-5=25.63%\n",
      "\tLR: 0.000976\n",
      "Best model saved (acc: 6.83%)\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "\tTrain: Loss=3.9137, Acc=9.75%\n",
      "\tVal:   Loss=3.8051, Top-1=11.83%, Top-5=38.90%\n",
      "\tLR: 0.000946\n",
      "Best model saved (acc: 11.83%)\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m trainer.build_model()\n\u001b[32m      4\u001b[39m trainer.setup_training()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m history = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Plant-Care-Assistant-App/ai/notebooks/../src/plant_care_ai/training/train.py:235\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m     correct += pred.eq(labels).sum().item()\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         pbar.set_postfix(\n\u001b[32m    236\u001b[39m             {\n\u001b[32m    237\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    238\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33macc\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[32m100.\u001b[39m\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39mcorrect\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    239\u001b[39m             }\n\u001b[32m    240\u001b[39m         )\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader), \u001b[32m100.0\u001b[39m * correct / total\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Plant-Care-Assistant-App/ai/notebooks/../src/plant_care_ai/training/train.py:286\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_best:\n\u001b[32m    285\u001b[39m         \u001b[38;5;28mself\u001b[39m.best_acc = val_acc\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         \u001b[38;5;28mself\u001b[39m.best_epoch = epoch\n\u001b[32m    288\u001b[39m     \u001b[38;5;28mself\u001b[39m.save_checkpoint(epoch, val_acc, val_top5, is_best=is_best)\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Path(\u001b[38;5;28mself\u001b[39m.checkpoint_dir / \u001b[33m\"\u001b[39m\u001b[33mhistory.json\u001b[39m\u001b[33m\"\u001b[39m).open(\n\u001b[32m    291\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    292\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Plant-Care-Assistant-App/ai/notebooks/../src/plant_care_ai/models/efficientnetv2.py:434\u001b[39m, in \u001b[36mEfficientNetV2.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    432\u001b[39m x = \u001b[38;5;28mself\u001b[39m.stem(x)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stages:\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     x = \u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m x = \u001b[38;5;28mself\u001b[39m.head(x)\n\u001b[32m    436\u001b[39m x = torch.flatten(x, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Plant-Care-Assistant-App/ai/notebooks/../src/plant_care_ai/models/efficientnetv2.py:235\u001b[39m, in \u001b[36mMBConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform forward pass.\u001b[39;00m\n\u001b[32m    226\u001b[39m \n\u001b[32m    227\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \n\u001b[32m    233\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_residual:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[38;5;28mself\u001b[39m.drop_path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.block(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = PlantTrainer(config)\n",
    "trainer.prepare_data()\n",
    "trainer.build_model()\n",
    "trainer.setup_training()\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a109b",
   "metadata": {},
   "source": [
    "^^ terrible accuracy and loss value :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b7b39b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 243916 samples, 1081 classes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\\\n",
    "checkpoint_path = \"../checkpoints/efficientnet_v2_top100/best.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "from plant_care_ai.training.class_selection import get_most_popular_classes\n",
    "data_path = \"../data/plantnet_300K\"\n",
    "top_100, _ = get_most_popular_classes(data_path, top_k=100)\n",
    "\n",
    "class_to_idx = {species_id: i for i, species_id in enumerate(top_100)}\n",
    "idx_to_class = {i: species_id for i, species_id in enumerate(top_100)}\n",
    "\n",
    "checkpoint[\"num_classes\"] = len(top_100)\n",
    "checkpoint[\"class_to_idx\"] = class_to_idx\n",
    "checkpoint[\"idx_to_class\"] = idx_to_class\n",
    "\n",
    "torch.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fceda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading plant names from: /home/szczuru/projects/Plant-Care-Assistant-App/ai/data/plantnet_300K/plantnet300K_species_id_2_name.json\n",
      "Loaded 1081 plant names\n",
      "Example: ('1355868', 'Lactuca virosa L.')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "mapping_file = data_path / \"plantnet300K_species_id_2_name.json\"\n",
    "print(f\"\\nLoading plant names from: {mapping_file}\")\n",
    "\n",
    "with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "    id_to_name = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(id_to_name)} plant names\")\n",
    "print(f\"Example: {list(id_to_name.items())[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b080d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /home/szczuru/projects/Plant-Care-Assistant-App/ai/checkpoints/efficientnet_v2_top100/best.pth\n",
      "Model: efficientnetv2\n",
      "Classes: 100\n",
      "Best validation accuracy: 11.83%\n",
      "\n",
      "Finding test image...\n",
      "Loaded 243916 samples, 1081 classes\n",
      "Test image: 15030c83645760de2d3b5d3665e2fbe511c7085b.jpg\n",
      "True class: Anthurium andraeanum Linden ex Andr√© (ID: 1409238)\n",
      "Processing time: 105.2ms\n",
      "\n",
      "1. Tagetes erecta L. (9.98%) \n",
      "   ID: 1374048\n",
      "2. Tagetes patula L. (8.33%) \n",
      "   ID: 1364159\n",
      "3. Papaver orientale L. (7.33%) \n",
      "   ID: 1394404\n",
      "4. Kniphofia uvaria (L.) Hook. (5.33%) \n",
      "   ID: 1393393\n",
      "5. Calendula officinalis L. (4.98%) \n",
      "   ID: 1357330\n",
      "Top prediction: {'class_id': '1374048', 'confidence': 0.0997985303401947, 'class_name': 'Tagetes erecta L.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "project_root = Path.cwd().parent \n",
    "data_path = project_root / \"data\" / \"plantnet_300K\"\n",
    "checkpoint_path = project_root / \"checkpoints\" / \"efficientnet_v2_top100\" / \"best.pth\"\n",
    "\n",
    "from plant_care_ai.inference.classifier import PlantClassifier\n",
    "classifier = PlantClassifier.from_checkpoint(checkpoint_path)\n",
    "classifier.set_name_mapping(id_to_name)\n",
    "\n",
    "print(\"\\nFinding test image...\")\n",
    "from plant_care_ai.data.dataset import PlantNetDataset\n",
    "from plant_care_ai.data.preprocessing import get_inference_pipeline\n",
    "\n",
    "dataset = PlantNetDataset(\n",
    "    str(data_path),\n",
    "    split=\"train\",\n",
    "    transform=get_inference_pipeline(224)\n",
    ")\n",
    "\n",
    "test_img_path = None\n",
    "true_species_id = None\n",
    "\n",
    "for img_path, species_id in dataset.paths:\n",
    "    if species_id in classifier.idx_to_class.values():\n",
    "        test_img_path = img_path\n",
    "        true_species_id = species_id\n",
    "        break\n",
    "\n",
    "print(f\"Test image: {Path(test_img_path).name}\")\n",
    "print(f\"True class: {id_to_name.get(true_species_id, 'Unknown')} (ID: {true_species_id})\")\n",
    "\n",
    "result = classifier.predict(test_img_path, top_k=5)\n",
    "\n",
    "print(f\"Processing time: {result['processing_time_ms']:.1f}ms\\n\")\n",
    "\n",
    "for rank, pred in enumerate(result['predictions'], 1):\n",
    "    is_correct = \"CORRECT\" if pred['class_id'] == true_species_id else \"\"\n",
    "    print(f\"{rank}. {pred.get('class_name', 'Unknown')} ({pred['confidence']:.2%}) {is_correct}\")\n",
    "    print(f\"   ID: {pred['class_id']}\")\n",
    "\n",
    "print(\"Top prediction:\", result['predictions'][0])\n",
    "\n",
    "from PIL import Image\n",
    "im = Image.open(test_img_path)\n",
    "im.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
